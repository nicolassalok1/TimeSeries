{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Machine-Learning-for-Time-Series-with-Python/blob/master/chapter7/XGBoost.ipynb\" target=\"_parent\\\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cjiXyuy5e2Fj",
    "outputId": "26e9d719-07e0-4a60-8005-c05a24e1e009",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:41:48.273915600Z",
     "start_time": "2025-05-30T08:29:15.449480Z"
    }
   },
   "source": [
    "!pip install xgboost"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution ~andas (/root/.local/lib/python3.12/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution ~andas (/root/.local/lib/python3.12/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0mRequirement already satisfied: xgboost in /root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages (3.0.0)\r\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages (from xgboost) (1.26.0)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages (from xgboost) (2.26.5)\r\n",
      "Requirement already satisfied: scipy in /root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages (from xgboost) (1.15.1)\r\n",
      "\u001B[33mWARNING: Ignoring invalid distribution ~andas (/root/.local/lib/python3.12/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution ~andas (/root/.local/lib/python3.12/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m\u001B[33mWARNING: Ignoring invalid distribution ~andas (/root/.local/lib/python3.12/site-packages)\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3CaAZqSGe2Fi",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:41:48.274420300Z",
     "start_time": "2025-05-30T08:35:20.885378Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.size\"] = \"17\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UpEJozDdyizN",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:41:48.245639Z",
     "start_time": "2025-05-30T08:39:37.718359Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # lèvera une exception claire en cas d'échec\n",
    "csv_data = StringIO(response.text)\n",
    "\n",
    "owid_covid = pd.read_csv(csv_data)\n",
    "owid_covid[\"date\"] = pd.to_datetime(owid_covid[\"date\"])\n",
    "df = (\n",
    "    owid_covid[owid_covid.location == \"France\"]\n",
    "    .set_index(\"date\", drop=True)\n",
    "    .resample(\"D\")\n",
    "    .interpolate(method=\"linear\")\n",
    "    .reset_index()\n",
    ")\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'freq_to_period_freqstr' from 'pandas._libs.tslibs.dtypes' (/root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages/pandas/_libs/tslibs/dtypes.cpython-312-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     10\u001B[39m owid_covid = pd.read_csv(csv_data)\n\u001B[32m     11\u001B[39m owid_covid[\u001B[33m\"\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m\"\u001B[39m] = pd.to_datetime(owid_covid[\u001B[33m\"\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m     12\u001B[39m df = (\n\u001B[32m     13\u001B[39m     owid_covid[owid_covid.location == \u001B[33m\"\u001B[39m\u001B[33mFrance\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     14\u001B[39m     .set_index(\u001B[33m\"\u001B[39m\u001B[33mdate\u001B[39m\u001B[33m\"\u001B[39m, drop=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     .resample(\u001B[33m\"\u001B[39m\u001B[33mD\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     16\u001B[39m     .interpolate(method=\u001B[33m\"\u001B[39m\u001B[33mlinear\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     17\u001B[39m     .reset_index()\n\u001B[32m     18\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/TimeSeries/lib/python3.12/site-packages/pandas/core/frame.py:11392\u001B[39m, in \u001B[36mresample\u001B[39m\u001B[34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset, group_keys)\u001B[39m\n\u001B[32m  11331\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcount\u001B[39m(\u001B[38;5;28mself\u001B[39m, axis: Axis = \u001B[32m0\u001B[39m, numeric_only: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m  11332\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m  11333\u001B[39m \u001B[33;03m    Count non-NA cells for each column or row.\u001B[39;00m\n\u001B[32m  11334\u001B[39m \n\u001B[32m  11335\u001B[39m \u001B[33;03m    The values `None`, `NaN`, `NaT`, ``pandas.NA`` are considered NA.\u001B[39;00m\n\u001B[32m  11336\u001B[39m \n\u001B[32m  11337\u001B[39m \u001B[33;03m    Parameters\u001B[39;00m\n\u001B[32m  11338\u001B[39m \u001B[33;03m    ----------\u001B[39;00m\n\u001B[32m  11339\u001B[39m \u001B[33;03m    axis : {0 or 'index', 1 or 'columns'}, default 0\u001B[39;00m\n\u001B[32m  11340\u001B[39m \u001B[33;03m        If 0 or 'index' counts are generated for each column.\u001B[39;00m\n\u001B[32m  11341\u001B[39m \u001B[33;03m        If 1 or 'columns' counts are generated for each row.\u001B[39;00m\n\u001B[32m  11342\u001B[39m \u001B[33;03m    numeric_only : bool, default False\u001B[39;00m\n\u001B[32m  11343\u001B[39m \u001B[33;03m        Include only `float`, `int` or `boolean` data.\u001B[39;00m\n\u001B[32m  11344\u001B[39m \n\u001B[32m  11345\u001B[39m \u001B[33;03m    Returns\u001B[39;00m\n\u001B[32m  11346\u001B[39m \u001B[33;03m    -------\u001B[39;00m\n\u001B[32m  11347\u001B[39m \u001B[33;03m    Series\u001B[39;00m\n\u001B[32m  11348\u001B[39m \u001B[33;03m        For each column/row the number of non-NA/null entries.\u001B[39;00m\n\u001B[32m  11349\u001B[39m \n\u001B[32m  11350\u001B[39m \u001B[33;03m    See Also\u001B[39;00m\n\u001B[32m  11351\u001B[39m \u001B[33;03m    --------\u001B[39;00m\n\u001B[32m  11352\u001B[39m \u001B[33;03m    Series.count: Number of non-NA elements in a Series.\u001B[39;00m\n\u001B[32m  11353\u001B[39m \u001B[33;03m    DataFrame.value_counts: Count unique combinations of columns.\u001B[39;00m\n\u001B[32m  11354\u001B[39m \u001B[33;03m    DataFrame.shape: Number of DataFrame rows and columns (including NA\u001B[39;00m\n\u001B[32m  11355\u001B[39m \u001B[33;03m        elements).\u001B[39;00m\n\u001B[32m  11356\u001B[39m \u001B[33;03m    DataFrame.isna: Boolean same-sized DataFrame showing places of NA\u001B[39;00m\n\u001B[32m  11357\u001B[39m \u001B[33;03m        elements.\u001B[39;00m\n\u001B[32m  11358\u001B[39m \n\u001B[32m  11359\u001B[39m \u001B[33;03m    Examples\u001B[39;00m\n\u001B[32m  11360\u001B[39m \u001B[33;03m    --------\u001B[39;00m\n\u001B[32m  11361\u001B[39m \u001B[33;03m    Constructing DataFrame from a dictionary:\u001B[39;00m\n\u001B[32m  11362\u001B[39m \n\u001B[32m  11363\u001B[39m \u001B[33;03m    >>> df = pd.DataFrame({\"Person\":\u001B[39;00m\n\u001B[32m  11364\u001B[39m \u001B[33;03m    ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\u001B[39;00m\n\u001B[32m  11365\u001B[39m \u001B[33;03m    ...                    \"Age\": [24., np.nan, 21., 33, 26],\u001B[39;00m\n\u001B[32m  11366\u001B[39m \u001B[33;03m    ...                    \"Single\": [False, True, True, True, False]})\u001B[39;00m\n\u001B[32m  11367\u001B[39m \u001B[33;03m    >>> df\u001B[39;00m\n\u001B[32m  11368\u001B[39m \u001B[33;03m       Person   Age  Single\u001B[39;00m\n\u001B[32m  11369\u001B[39m \u001B[33;03m    0    John  24.0   False\u001B[39;00m\n\u001B[32m  11370\u001B[39m \u001B[33;03m    1    Myla   NaN    True\u001B[39;00m\n\u001B[32m  11371\u001B[39m \u001B[33;03m    2   Lewis  21.0    True\u001B[39;00m\n\u001B[32m  11372\u001B[39m \u001B[33;03m    3    John  33.0    True\u001B[39;00m\n\u001B[32m  11373\u001B[39m \u001B[33;03m    4    Myla  26.0   False\u001B[39;00m\n\u001B[32m  11374\u001B[39m \n\u001B[32m  11375\u001B[39m \u001B[33;03m    Notice the uncounted NA values:\u001B[39;00m\n\u001B[32m  11376\u001B[39m \n\u001B[32m  11377\u001B[39m \u001B[33;03m    >>> df.count()\u001B[39;00m\n\u001B[32m  11378\u001B[39m \u001B[33;03m    Person    5\u001B[39;00m\n\u001B[32m  11379\u001B[39m \u001B[33;03m    Age       4\u001B[39;00m\n\u001B[32m  11380\u001B[39m \u001B[33;03m    Single    5\u001B[39;00m\n\u001B[32m  11381\u001B[39m \u001B[33;03m    dtype: int64\u001B[39;00m\n\u001B[32m  11382\u001B[39m \n\u001B[32m  11383\u001B[39m \u001B[33;03m    Counts for each **row**:\u001B[39;00m\n\u001B[32m  11384\u001B[39m \n\u001B[32m  11385\u001B[39m \u001B[33;03m    >>> df.count(axis='columns')\u001B[39;00m\n\u001B[32m  11386\u001B[39m \u001B[33;03m    0    3\u001B[39;00m\n\u001B[32m  11387\u001B[39m \u001B[33;03m    1    2\u001B[39;00m\n\u001B[32m  11388\u001B[39m \u001B[33;03m    2    3\u001B[39;00m\n\u001B[32m  11389\u001B[39m \u001B[33;03m    3    3\u001B[39;00m\n\u001B[32m  11390\u001B[39m \u001B[33;03m    4    3\u001B[39;00m\n\u001B[32m  11391\u001B[39m \u001B[33;03m    dtype: int64\u001B[39;00m\n\u001B[32m> \u001B[39m\u001B[32m11392\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m  11393\u001B[39m     axis = \u001B[38;5;28mself\u001B[39m._get_axis_number(axis)\n\u001B[32m  11395\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m numeric_only:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/TimeSeries/lib/python3.12/site-packages/pandas/core/generic.py:8855\u001B[39m, in \u001B[36mresample\u001B[39m\u001B[34m(self, rule, axis, closed, label, convention, kind, loffset, base, on, level, origin, offset, group_keys)\u001B[39m\n\u001B[32m      0\u001B[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/TimeSeries/lib/python3.12/site-packages/pandas/core/resample.py:27\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_libs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m lib\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_libs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtslibs\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[32m     19\u001B[39m     BaseOffset,\n\u001B[32m     20\u001B[39m     IncompatibleFrequency,\n\u001B[32m   (...)\u001B[39m\u001B[32m     25\u001B[39m     to_offset,\n\u001B[32m     26\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_libs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtslibs\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdtypes\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m freq_to_period_freqstr\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_typing\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m NDFrameT\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mcompat\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m function \u001B[38;5;28;01mas\u001B[39;00m nv\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'freq_to_period_freqstr' from 'pandas._libs.tslibs.dtypes' (/root/miniconda3/envs/TimeSeries/lib/python3.12/site-packages/pandas/_libs/tslibs/dtypes.cpython-312-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WqB6Vwn3e2Fj"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from typing import List\n",
    "\n",
    "class DateFeatures(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"DateFeatures transformer.\"\"\"\n",
    "    features = [\n",
    "        \"hour\",\n",
    "        \"year\",\n",
    "        \"day\",\n",
    "        \"weekday\",\n",
    "        \"month\",\n",
    "        \"quarter\",\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Nothing much to do.\"\"\"\n",
    "        super().__init__()\n",
    "        self.feature_names: List[str] = []\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Feature names.\"\"\"\n",
    "        return self.feature_names\n",
    "        \n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        \"\"\"Annotate date features.\"\"\"\n",
    "        Xt = []\n",
    "        for col in df.columns:\n",
    "            for feature in self.features:\n",
    "                date_feature = getattr(\n",
    "                    getattr(\n",
    "                        df[col], \"dt\"\n",
    "                    ), feature\n",
    "                )\n",
    "                date_feature.name = f\"{col}_{feature}\"\n",
    "                Xt.append(date_feature)\n",
    "        \n",
    "        df2 = pd.concat(Xt, axis=1)\n",
    "        self.feature_names = list(df2.columns)\n",
    "        return df2\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None, **fit_params):\n",
    "        \"\"\"No fitting needed.\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IhEkSi5azUrM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from typing import Dict\n",
    "\n",
    "class CyclicalFeatures(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"CyclicalFeatures transformer.\"\"\"\n",
    "    \n",
    "    def __init__(self, max_vals: Dict[str, float] = {}):\n",
    "        \"\"\"Nothing much to do.\"\"\"\n",
    "        super().__init__()\n",
    "        self.feature_names: List[str] = []\n",
    "        self.max_vals = max_vals\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Feature names.\"\"\"\n",
    "        return self.feature_names\n",
    "        \n",
    "    def transform(self, df: pd.DataFrame):\n",
    "        \"\"\"Annotate date features.\"\"\"\n",
    "        Xt = []\n",
    "        for col in df.columns:\n",
    "            if col in self.max_vals:\n",
    "                max_val = self.max_vals[col]\n",
    "            else:\n",
    "                max_val = df[col].max()\n",
    "            for fun_name, fun in [(\"cos\", np.cos), (\"sin\", np.sin)]:\n",
    "                date_feature = fun(2 * np.pi * df[col] / max_val)\n",
    "                date_feature.name = f\"{col}_{fun_name}\"\n",
    "                Xt.append(date_feature)\n",
    "        \n",
    "        df2 = pd.concat(Xt, axis=1)\n",
    "        self.feature_names = list(df2.columns)\n",
    "        return df2\n",
    "\n",
    "    def fit(self, df: pd.DataFrame, y=None, **fit_params):\n",
    "        \"\"\"No fitting needed.\"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87bELgcAziFi"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "#from sklearn import linear_model\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\n",
    "        \"date\",\n",
    "        make_pipeline(\n",
    "            DateFeatures(),\n",
    "            ColumnTransformer(transformers=[\n",
    "                (\"cyclical\", CyclicalFeatures(),\n",
    "                  [\"date_day\", \"date_weekday\", \"date_month\"]\n",
    "                )\n",
    "            ], remainder=\"passthrough\")\n",
    "        ), [\"date\"],\n",
    "  ),], remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        #(\"clf\", linear_model.LinearRegression(),),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvhfdtVre2Fj",
    "outputId": "453afa7a-c3f5-4a51-f693-55d2b7698282"
   },
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\"date\"]\n",
    "date_features = pipeline.fit_transform(df[FEATURE_COLS])\n",
    "date_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmhAZE-Me2Fk"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = int(len(df) * 0.9)\n",
    "HORIZON = 1\n",
    "TARGET_COL = \"new_cases\"\n",
    "\n",
    "X_train, X_test = df.iloc[HORIZON:TRAIN_SIZE], df.iloc[TRAIN_SIZE+HORIZON:]\n",
    "y_train = df.shift(periods=HORIZON).iloc[HORIZON:TRAIN_SIZE][TARGET_COL]\n",
    "y_test = df.shift(periods=HORIZON).iloc[TRAIN_SIZE+HORIZON:][TARGET_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aA7GL52je2Fl",
    "outputId": "d19d55fd-a683-4eea-a087-5676a4333077"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"xgb\", XGBRegressor(objective=\"reg:squarederror\", n_estimators=1000))\n",
    "    ]\n",
    ")\n",
    "pipeline.fit(X_train[FEATURE_COLS], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b3PUD4CH5Gx"
   },
   "outputs": [],
   "source": [
    "MAX_HORIZON = 90\n",
    "X_test_horizon = pd.Series(pd.date_range(\n",
    "    start=df.date.min(), \n",
    "    periods=len(df) + MAX_HORIZON,\n",
    "    name=\"date\"\n",
    ")).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8VoXOzCe2Fl"
   },
   "outputs": [],
   "source": [
    "forecasted = pd.concat(\n",
    "    [pd.Series(pipeline.predict(X_test_horizon[FEATURE_COLS])), pd.Series(X_test_horizon.date)],\n",
    "    axis=1\n",
    ")\n",
    "forecasted.columns = [TARGET_COL, \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FGnoSbre2Fl"
   },
   "outputs": [],
   "source": [
    "actual = pd.concat(\n",
    "    [pd.Series(df[TARGET_COL]), pd.Series(df.date)],\n",
    "    axis=1\n",
    ")\n",
    "actual.columns = [TARGET_COL, \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "XtTKGkoTe2Fm",
    "outputId": "4c3c830f-3df9-4c5b-ad06-41cd623e5e70"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "forecasted.set_index(\"date\").plot(linestyle='--', ax=ax)\n",
    "actual.set_index(\"date\").plot(linestyle='-.', ax=ax)\n",
    "plt.legend([\"forecast\", \"actual\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4oPSOTse2F1",
    "outputId": "ad6760a9-e9a8-4cd8-812f-39fce7c4e636"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_data = actual.merge(forecasted, on=\"date\", suffixes=(\"_actual\", \"_predicted\"))\n",
    "\n",
    "mse = mean_squared_error(test_data.new_cases_actual, test_data.new_cases_predicted, squared=False)  # RMSE\n",
    "print(\"The root mean squared error (RMSE) on test set: {:.2f}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU1DQT1o5Vpn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "XGBoost",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
