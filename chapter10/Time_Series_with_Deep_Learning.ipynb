{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/PacktPublishing/Machine-Learning-for-Time-Series-with-Python/blob/master/chapter10/Time_Series_with_Deep_Learning.ipynb\" target=\"_parent\\\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:44.100809Z",
     "start_time": "2025-05-30T08:29:44.098425Z"
    }
   },
   "source": [
    "# from https://github.com/FinYang/tsdl/blob/56e091544cb81e573ee6db20c6f9cd39c70e6243/data-raw/boxjenk/seriesg.dat"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jEiBBpYjLCj3",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:44.151608Z",
     "start_time": "2025-05-30T08:29:44.147965Z"
    }
   },
   "source": [
    "values = [         \n",
    "  112., 118., 132., 129., 121., 135., 148., 148., 136., 119., 104., 118., 115., 126.,\n",
    "  141., 135., 125., 149., 170., 170., 158., 133., 114., 140., 145., 150., 178., 163.,\n",
    "  172., 178., 199., 199., 184., 162., 146., 166., 171., 180., 193., 181., 183., 218.,\n",
    "  230., 242., 209., 191., 172., 194., 196., 196., 236., 235., 229., 243., 264., 272.,\n",
    "  237., 211., 180., 201., 204., 188., 235., 227., 234., 264., 302., 293., 259., 229.,\n",
    "  203., 229., 242., 233., 267., 269., 270., 315., 364., 347., 312., 274., 237., 278.,\n",
    "  284., 277., 317., 313., 318., 374., 413., 405., 355., 306., 271., 306., 315., 301.,\n",
    "  356., 348., 355., 422., 465., 467., 404., 347., 305., 336., 340., 318., 362., 348.,\n",
    "  363., 435., 491., 505., 404., 359., 310., 337., 360., 342., 406., 396., 420., 472.,\n",
    "  548., 559., 463., 407., 362., 405., 417., 391., 419., 461., 472., 535., 622., 606.,\n",
    "  508., 461., 390., 432.,\n",
    " ]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9bBfTTdMK9AE",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:44.242988Z",
     "start_time": "2025-05-30T08:29:44.238048Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "idx = pd.date_range(\"1949-01-01\", periods=len(values), freq=\"M\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29926/1958446250.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  idx = pd.date_range(\"1949-01-01\", periods=len(values), freq=\"M\")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z3sG4R4VKnWT",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:44.292837Z",
     "start_time": "2025-05-30T08:29:44.289734Z"
    }
   },
   "source": [
    "passengers = pd.Series(values, index=idx, name=\"passengers\").to_frame()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PBlu9I2p8uib",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:44.436712Z",
     "start_time": "2025-05-30T08:29:44.375671Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(passengers, passengers.passengers.shift(-1), shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DkejrcL8aFt1",
    "ExecuteTime": {
     "end_time": "2025-05-30T08:29:46.270733Z",
     "start_time": "2025-05-30T08:29:44.505858Z"
    }
   },
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "DROPOUT_RATIO = 0.2\n",
    "HIDDEN_NEURONS = 10\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "def create_model(passengers):\n",
    "  input_layer = keras.layers.Input(len(passengers.columns))\n",
    "\n",
    "  hiden_layer = keras.layers.Dropout(DROPOUT_RATIO)(input_layer)\n",
    "  hiden_layer = keras.layers.Dense(HIDDEN_NEURONS, activation='relu')(hiden_layer)\n",
    "\n",
    "  output_layer = keras.layers.Dropout(DROPOUT_RATIO)(hiden_layer)\n",
    "  output_layer = keras.layers.Dense(1)(output_layer)\n",
    "\n",
    "  model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "  model.compile(loss='mse', optimizer=keras.optimizers.Adagrad(),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(), keras.metrics.MeanAbsoluteError()])\n",
    "  return model\n",
    "\n",
    "model = create_model(passengers)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 10:29:44.719510: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 10:29:44.727797: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748593784.737346   29926 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748593784.740274   29926 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748593784.747627   29926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748593784.747650   29926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748593784.747652   29926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748593784.747653   29926 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-30 10:29:44.750387: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '1' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 24\u001B[39m\n\u001B[32m     20\u001B[39m   model.compile(loss=\u001B[33m'\u001B[39m\u001B[33mmse\u001B[39m\u001B[33m'\u001B[39m, optimizer=keras.optimizers.Adagrad(),\n\u001B[32m     21\u001B[39m     metrics=[keras.metrics.RootMeanSquaredError(), keras.metrics.MeanAbsoluteError()])\n\u001B[32m     22\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m model\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m model = create_model(passengers)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mcreate_model\u001B[39m\u001B[34m(passengers)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcreate_model\u001B[39m(passengers):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m   input_layer = keras.layers.Input(\u001B[38;5;28mlen\u001B[39m(passengers.columns))\n\u001B[32m     12\u001B[39m   hiden_layer = keras.layers.Dropout(DROPOUT_RATIO)(input_layer)\n\u001B[32m     13\u001B[39m   hiden_layer = keras.layers.Dense(HIDDEN_NEURONS, activation=\u001B[33m'\u001B[39m\u001B[33mrelu\u001B[39m\u001B[33m'\u001B[39m)(hiden_layer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:209\u001B[39m, in \u001B[36mInput\u001B[39m\u001B[34m(shape, batch_size, dtype, sparse, ragged, batch_shape, name, tensor, optional)\u001B[39m\n\u001B[32m    144\u001B[39m \u001B[38;5;129m@keras_export\u001B[39m([\u001B[33m\"\u001B[39m\u001B[33mkeras.layers.Input\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mkeras.Input\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mInput\u001B[39m(\n\u001B[32m    146\u001B[39m     shape=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    154\u001B[39m     optional=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    155\u001B[39m ):\n\u001B[32m    156\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Used to instantiate a Keras tensor.\u001B[39;00m\n\u001B[32m    157\u001B[39m \n\u001B[32m    158\u001B[39m \u001B[33;03m    A Keras tensor is a symbolic tensor-like object, which we augment with\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    207\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    208\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m     layer = InputLayer(\n\u001B[32m    210\u001B[39m         shape=shape,\n\u001B[32m    211\u001B[39m         batch_size=batch_size,\n\u001B[32m    212\u001B[39m         dtype=dtype,\n\u001B[32m    213\u001B[39m         sparse=sparse,\n\u001B[32m    214\u001B[39m         ragged=ragged,\n\u001B[32m    215\u001B[39m         batch_shape=batch_shape,\n\u001B[32m    216\u001B[39m         name=name,\n\u001B[32m    217\u001B[39m         input_tensor=tensor,\n\u001B[32m    218\u001B[39m         optional=optional,\n\u001B[32m    219\u001B[39m     )\n\u001B[32m    220\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m layer.output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/keras/src/layers/core/input_layer.py:92\u001B[39m, in \u001B[36mInputLayer.__init__\u001B[39m\u001B[34m(self, shape, batch_size, dtype, sparse, ragged, batch_shape, input_tensor, optional, name, **kwargs)\u001B[39m\n\u001B[32m     89\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mYou must pass a `shape` argument.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     91\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m         shape = backend.standardize_shape(shape)\n\u001B[32m     93\u001B[39m         batch_shape = (batch_size,) + shape\n\u001B[32m     95\u001B[39m \u001B[38;5;28mself\u001B[39m._batch_shape = backend.standardize_shape(batch_shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/lib/python3.12/site-packages/keras/src/backend/common/variables.py:562\u001B[39m, in \u001B[36mstandardize_shape\u001B[39m\u001B[34m(shape)\u001B[39m\n\u001B[32m    560\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mUndefined shapes are not supported.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    561\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(shape, \u001B[33m\"\u001B[39m\u001B[33m__iter__\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m562\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCannot convert \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m to a shape.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    563\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m config.backend() == \u001B[33m\"\u001B[39m\u001B[33mtensorflow\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    564\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(shape, tf.TensorShape):\n\u001B[32m    565\u001B[39m         \u001B[38;5;66;03m# `tf.TensorShape` may contain `Dimension` objects.\u001B[39;00m\n\u001B[32m    566\u001B[39m         \u001B[38;5;66;03m# We need to convert the items in it to either int or `None`\u001B[39;00m\n",
      "\u001B[31mValueError\u001B[39m: Cannot convert '1' to a shape."
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJCCbRTib8Up",
    "outputId": "63136aae-e096-4ff3-f4fb-2d728054d099"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=1000, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgHreXsUdc6a"
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJC6mB74dkh9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_result(y_test, predicted):\n",
    "  plt.figure(figsize=(16, 6))\n",
    "  plt.plot(y_test.index, predicted, 'o-', label=\"predicted\")\n",
    "  plt.plot(y_test.index, y_test, '.-', label=\"actual\")\n",
    "\n",
    "  plt.ylabel(\"Passengers\")\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 396
    },
    "id": "4spy29-UdzRS",
    "outputId": "86904074-d6ec-48a2-ab70-d5085ff21535"
   },
   "outputs": [],
   "source": [
    "show_result(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mh4E54N_egps",
    "outputId": "3930edda-49da-4ba5-ba5b-2d9c09241a94"
   },
   "outputs": [],
   "source": [
    "passengers[\"month\"] = passengers.index.month.values\n",
    "passengers[\"year\"] = passengers.index.year.values\n",
    "\n",
    "model = create_model(passengers)\n",
    "X_train, X_test, y_train, y_test = train_test_split(passengers, passengers.passengers.shift(-1), shuffle=False)\n",
    "model.fit(X_train, y_train, epochs=100, callbacks=[callback])\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "Y9_1dwAofTM7",
    "outputId": "6f8515de-b3d6-4aee-a65b-cde8dc442631"
   },
   "outputs": [],
   "source": [
    "show_result(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eSnjPMYrcbN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "DROPOUT_RATIO = 0.1\n",
    "HIDDEN_NEURONS = 5\n",
    "\n",
    "\n",
    "def create_model(passengers):\n",
    "  scale = tf.constant(passengers.passengers.std())\n",
    "\n",
    "  continuous_input_layer = keras.layers.Input(shape=1)\n",
    "\n",
    "  categorical_input_layer = keras.layers.Input(shape=1)\n",
    "  embedded = keras.layers.Embedding(12, 5)(categorical_input_layer)\n",
    "  embedded_flattened = keras.layers.Flatten()(embedded)\n",
    "\n",
    "  year_input = keras.layers.Input(shape=1)\n",
    "  year_layer = keras.layers.Dense(1)(year_input)\n",
    "\n",
    "  hidden_output = keras.layers.Concatenate(-1)([embedded_flattened, year_layer, continuous_input_layer])\n",
    "  output_layer = keras.layers.Dense(1)(hidden_output)\n",
    "  output = output_layer * scale + continuous_input_layer\n",
    "\n",
    "  model = keras.models.Model(inputs=[\n",
    "    continuous_input_layer, categorical_input_layer, year_input\n",
    "  ], outputs=output)\n",
    "\n",
    "  model.compile(loss='mse', optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(), keras.metrics.MeanAbsoluteError()])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSyGPARMt9zx",
    "outputId": "df8b02fb-fc3a-49da-ac2f-d6e951eca334"
   },
   "outputs": [],
   "source": [
    "passengers = pd.Series(values, index=idx, name=\"passengers\").to_frame()\n",
    "passengers[\"year\"] = passengers.index.year.values - passengers.index.year.values.min()\n",
    "passengers[\"month\"] = passengers.index.month.values - 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(passengers, passengers.passengers.shift(-1), shuffle=False)\n",
    "model = create_model(X_train)\n",
    "model.fit(\n",
    "  (X_train[\"passengers\"], X_train[\"year\"], X_train[\"month\"]),\n",
    "  y_train, epochs=1000,\n",
    "  callbacks=[callback]\n",
    ")\n",
    "predicted = model.predict((X_test[\"passengers\"], X_test[\"year\"], X_test[\"month\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "D2fH073LAYYc",
    "outputId": "c3bc19a2-7bf6-47dc-f753-75fdfb215aa2"
   },
   "outputs": [],
   "source": [
    "show_result(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMfFWDb8Vs6x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Time-Series with Deep Learning",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
